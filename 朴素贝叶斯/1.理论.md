# 贝叶斯决策论
贝叶斯决策论是概率框架下的实施决策的基本方法，我们以为多分类任务为例来解其基本原理

假设有N种可能的类别标记，即：$y=\{ c_{1},c_{2}, \dots ,c_{N}\}$，$\lambda_{ij}$是将标记为$c_j$的样本误判为$c_i$的损失。基于后验概率$P(c_i|x)$可以算出将样本$x$分类为$c_i$所产生的期望损失，即在样本$x$上的条件风险。

$$R(c_i|x)=\sum_{j=1}^N \lambda_{ij}P(c_j|x)$$

我们的任务是寻找一个判定准则h以最小化整体风险，只需在每个样本上选择使条件风险最小的类别标记即可。此时$h^*$被称为是贝叶斯最优分类器。
$$h^*=arg \min_{c} R(c|x)$$

误判损失的形式如果确定下来
$$\lambda_{ij}=\begin{cases}
    0,if i=j \\1,other wise
\end{cases}$$

那么贝叶斯最优分类器为：
$$h^*=\argmax_{c\in y}P(c|x)$$
即是说对每个样本选择贝叶斯后验概率最大的类别

由贝叶斯定理：
$$P(c|x)=\frac{P(x|c)P(c)}{P(x)}$$
$P(x|c)$称为似然，问题的关键是求似然值。

## 朴素贝叶斯
朴素贝叶斯是对类条件分布有着重要的假设，其中包括概率分布形式以及属性条件独立性，这样贝叶斯决策问题就变为参数估计问题。

